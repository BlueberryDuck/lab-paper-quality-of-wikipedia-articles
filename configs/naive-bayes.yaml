start_step: "data_loader"
load:
  data_file: "preprocessed_data.csv"
  features_file: "features.pkl"
  model_file: ""

data_loader:
  good_file: "data/raw/good.csv"
  promo_file: "data/raw/promotional.csv"
  shuffle: true
  save: "loaded_data.csv"

preprocessing:
  remove_stopwords: false # didn't change kpis
  apply_stemming: false # didn't change kpis
  remove_numbers: false # removing numbers lowered f1 by 0.01 with max_features 10_000
  save: "preprocessed_data.csv"

vectorizer:
  type: tfidf # tfidf higher precision and count higher recall by 0.1 each
  max_features: 10_000 # 100_000: 0.88 10_000: 0.88 1_000: 0.86 100:0.77
  ngram_range: [1, 1] # 1,2 decreased precision by 0.01 and took significantly longer
  min_df: 0.001 # too high decreased f1 significantly
  max_df: 0.9 # too low decreased f1 by 0.01
  # 0.001 and 0.9 increased recall by 0.01
  save: "features.pkl"

naive_bayes:
  alpha: 1.0 # 0.5 lowered decreased recall by 0.1 above 1 decreased precision by 0.1
  save: "naive_bayes_model.pkl"

evaluation:
  save: "evaluation.png"

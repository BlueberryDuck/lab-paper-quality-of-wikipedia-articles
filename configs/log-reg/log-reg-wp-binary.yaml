# configs/log-reg/log-reg-wp-binary.yaml

usecase: "binary"
start_step: "model"

data_loader:
  good_file: "data/wp/good_sample.csv"
  promo_file: "data/wp/promotional_sample.csv"
  neutral_file: "data/wp/neutral_sample.csv"
  shuffle: false
  save: "loaded_data_wp_binary.csv"

preprocessing:
  remove_non_word: true
  convert_lowercase: true
  remove_stopwords: true
  apply_stemming: true
  remove_numbers: false
  remove_whitespace: true
  save: "preprocessed_data_wp_binary.csv"

features:
  type: tfidf
  ngram_range: [1, 1]
  max_df: 0.9
  min_df: 0.001
  max_features: 10_000
  sublinear_tf: true
  save: "features_wp_binary.pkl"

model:
  type: logistic_regression
  test_size: 0.2
  random_state: 42
  grid_search: true
  param_grid:
    penalty: ["l1", "l2"]
    solver: ["liblinear", "saga"]
    max_iter: [500, 1000]
  save: "model_lr_wp_binary.pkl"

evaluation:
  save: "evaluation_lr_wp_binary.png"
# 2025-03-10 21:42:46,790 - src.models.logistic_regression - INFO - Trained LogisticRegression model with {'max_iter': 500, 'penalty': 'l1', 'solver': 'saga'}
# 2025-03-10 21:42:46,819 - src.evaluation - INFO - Accuracy: 89.65%
# 2025-03-10 21:42:46,825 - src.evaluation - INFO - Classification Report:
#               precision    recall  f1-score   support

#            0       0.93      0.96      0.94      5942
#            1       0.89      0.89      0.89      6060
#            2       0.87      0.84      0.86      5998

#     accuracy                           0.90     18000
#    macro avg       0.90      0.90      0.90     18000
# weighted avg       0.90      0.90      0.90     18000

# 2025-03-10 21:42:46,827 - src.evaluation - INFO - Confusion Matrix:
# [[5733   59  150]
#  [ 116 5369  575]
#  [ 348  615 5035]]

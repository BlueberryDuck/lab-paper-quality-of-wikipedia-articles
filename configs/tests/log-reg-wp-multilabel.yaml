# configs/tests/log-reg-wp-multilabel.yaml

uusecase: "multilabel"
start_step: "model"

data_loader:
  promo_file: "data/wp/promotional_sample.csv"
  shuffle: false
  save: "loaded_data_wp_multilabel.csv"

preprocessing:
  remove_non_word: true
  convert_lowercase: true
  remove_stopwords: true
  apply_stemming: true
  remove_numbers: false
  remove_whitespace: true
  save: "preprocessed_data_wp_multilabel.csv"

features:
  type: tfidf
  ngram_range: [1, 1]
  max_df: 0.9
  min_df: 0.001
  max_features: 10_000
  sublinear_tf: true
  save: "features_wp_multilabel.pkl"

model:
  type: logistic_regression
  test_size: 0.2
  random_state: 42
  grid_search: true
  param_grid:
    penalty: ["l1", "l2"]
    solver: ["liblinear", "saga"]
    max_iter: [500, 1000]
  save: "model_lr_wp_binary.pkl"

evaluation:
  save: "evaluation_lr_wp_multilabel.png"
# 2025-03-07 06:44:58,293 - src.models.logistic_regression - INFO - Trained LogisticRegression model with {'estimator__max_iter': 1000, 'estimator__penalty': 'l1', 'estimator__solver': 'saga'}
# 2025-03-07 06:44:58,313 - src.evaluation - INFO - Accuracy: 50.35%
# 2025-03-07 06:44:58,319 - src.evaluation - INFO - Classification Report:
#               precision    recall  f1-score   support

#            0       0.73      0.77      0.75      3031
#            1       0.60      0.42      0.49      2380
#            2       0.67      0.09      0.15       117
#            3       0.00      0.00      0.00       113
#            4       0.58      0.29      0.39       717

#    micro avg       0.68      0.56      0.61      6358
#    macro avg       0.52      0.31      0.36      6358
# weighted avg       0.65      0.56      0.59      6358
#  samples avg       0.57      0.57      0.56      6358

# 2025-03-07 06:44:58,321 - src.evaluation - INFO - Confusion Matrix:
# [[[2125  844]
#   [ 705 2326]]

#  [[2970  650]
#   [1390  990]]

#  [[5878    5]
#   [ 107   10]]

#  [[5887    0]
#   [ 113    0]]

#  [[5132  151]
#   [ 507  210]]]

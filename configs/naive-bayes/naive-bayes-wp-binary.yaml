# configs/naive-bayes/naive-bayes-wp-binary.yaml

usecase: "binary"
start_step: "model"

data_loader:
  good_file: "data/wp/good_sample.csv"
  promo_file: "data/wp/promotional_sample.csv"
  neutral_file: "data/wp/neutral_sample.csv"
  shuffle: false
  save: "loaded_data_wp_binary.csv"

preprocessing:
  remove_non_word: true
  convert_lowercase: true
  remove_stopwords: true
  apply_stemming: true
  remove_numbers: false
  remove_whitespace: true
  save: "preprocessed_data_wp_binary.csv"

features:
  type: tfidf
  ngram_range: [1, 1]
  max_df: 0.9
  min_df: 0.001
  max_features: 10_000
  sublinear_tf: true
  save: "features_wp_binary.pkl"

model:
  type: naive_bayes
  test_size: 0.2
  random_state: 42
  grid_search: true
  param_grid:
    alpha: [0.01, 0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0]
    fit_prior: [true, false]
  save: "model_nb_wp_binary.pkl"

evaluation:
  save: "evaluation_nb_wp_binary.png"
# 2025-03-10 20:41:47,264 - src.models.naive_bayes - INFO - Trained Naive Bayes model with {'alpha': 2.5, 'fit_prior': True}
# 2025-03-10 20:41:47,308 - src.evaluation - INFO - Accuracy: 79.51%
# 2025-03-10 20:41:47,315 - src.evaluation - INFO - Classification Report:
#               precision    recall  f1-score   support

#            0       0.79      0.86      0.82      5942
#            1       0.80      0.86      0.83      6060
#            2       0.80      0.66      0.72      5998

#     accuracy                           0.80     18000
#    macro avg       0.80      0.80      0.79     18000
# weighted avg       0.80      0.80      0.79     18000

# 2025-03-10 20:41:47,317 - src.evaluation - INFO - Confusion Matrix:
# [[5136  300  506]
#  [ 368 5223  469]
#  [1012 1033 3953]]

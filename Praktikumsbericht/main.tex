\documentclass[researchlab,palatino]{AIGpaper}
% Please read the README.md file for additional information on the parameters and overall usage of AIGpaper

%%%% Package Imports %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{graphicx}					    % enhanced support for graphics
\usepackage{tabularx}				      	% more flexible tabular
\usepackage{amsfonts}					    % math fonts
\usepackage{amssymb}					    % math symbols
\usepackage{amsmath}                        % overall enhancements to math environment
\usepackage{amsthm}                         % Nutzung von Definition
\usepackage{hyperref}                       % Zeilenumbruch in URL
\usepackage{xurl}                           % Nach hyperref laden

%%%% optional packages
\usepackage{tikz}                           % creating graphs and other structures
\usetikzlibrary{arrows,positioning}
\tikzset{
    %Define standard arrow tip
    >=stealth',
    %Define style for argument
    args/.style={circle, minimum size=0.9cm,draw=black, thick,fill=white},
}


%%%% Author and Title Information %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\author{Robin Suxdorf \and Sebastian Bunge \and Johannes Krämer \and Emmanuelle Steenhof \and Alexander Kunze}

\title{Web Science - Die Qualität von Wikipedia-Artikeln}


%%%% Abstract %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\germanabstract{
Erstmal nur ein Draft. Inhalte werden weiter abgestimmt. 
}

% use this if the document is written in english
%\englishabstract{}


\begin{document}

\maketitle % prints title and author information, as well as the abstract 


% ===================== Beginning of the actual text section =====================

\section{Einleitung}

Das Ziel dieses Projektpraktikums ist die praktische Anwendung von Methoden des maschinellen Lernens auf einen vorgegebenen Datensatz aus dem Bereich der Web Science. Wir haben uns für das Thema \textbf{Qualität von Wikipedia-Artikeln} entschieden und nutzen dafür den Datensatz von Kaggle: \url{https://www.kaggle.com/datasets/urbanbricks/wikipedia-promotional-articles}\\
Im Rahmen dieses Projekts bearbeiten wir folgende Teilaufgaben:

\begin{enumerate} 
\item \textbf{Analyse des Datensatzes und Identifizierung einer geeigneten Problemstellung}: Wir untersuchen den bereitgestellten Datensatz eingehend, um ein maschinelles Lernproblem zu formulieren, das mit den vorhandenen Daten gelöst werden kann. 
\item \textbf{Aufbereitung und Vorverarbeitung des Datensatzes}: Wir bereinigen und transformieren die Daten, um sie für die Modellierung vorzubereiten. 
\item \textbf{Anwendung von drei klassischen Methoden des maschinellen Lernens}: Basierend auf den Inhalten der Kapitel 2 und 3 des Kurses \glqq Einführung in Maschinelles Lernen\grqq{} implementieren wir drei klassische Algorithmen, um die identifizierte Problemstellung zu adressieren. 
\item \textbf{Anwendung eines Deep-Learning-Ansatzes}: Wir recherchieren einen geeigneten Deep-Learning-Ansatz, setzen diesen um und wenden diesen auf die Problemstellung an
\item \textbf{Entwickeln eines eigenen Ansatzes}: Im Rahmen dieser Ausarbeitung wird ein eigener Ansatz für die Problemstellung entwickelt und beschrieben. 
\item \textbf{Interpretation und Diskussion der Ergebnisse}: Basierend auf den bisherigen Resultaten entwickeln wir eine neue Idee für einen passenden Ansatz, beispielsweise eine neue Architektur für ein neuronales Netzwerk, die wir implementieren und anwenden. \end{enumerate}

\section{Aufgabenverteilung}
Im Kick-Off Meeting wurde Robin Suxdorf als Teamleiter und Kommunikationskanal zu den Praktikumsbetreuern gewählt.  Für die Umsetzung der Teilaufgaben wurden jeweils verantwortliche bestimmt:
\begin{enumerate}
    \item Klassische Methode 1: Ansatz: Bayes Leiter: Sebastian Bunge
    \item Klassische Methode 2: Ansatz: SVM Leiter: Johannes Krämer
    \item Klassische Methode 3: Ansatz: Logistische Regression Leiter: Alexander Kunte
    \item Deep-Learning Methode: LSTM Transformer oder Ansatz über Embeddings; Zuerst einmal werden Embeddings angeschaut Leiter Robin Suxdorf
    \item Eigener Ansatz: wird noch genauer angeschaut Leiter: Emmanuelle Steenhof
\end{enumerate}
Während des gesamten Praktikums schreibt Alexander Kunze fortlaufend den Praktikumsbericht weiter.
-Weitere Themen: Präsentation, Vorträge, usw. 
\section{Teaminterne Organisation}
Im Rahmen des Kick-Offs wurde beschlossen, dass Discord (bereitgestellt über Alexander Kunze und Github (bereitgestellt von Robin Suxdorf) als Kollaborationsplattformen dienen. Ein wöchentlicher Jour-Fixe sichert den regelmäßigen Austausch. Jeder Teilnehmer verantwortet die Weiterentwicklung seiner Methode. Das bedeutet, er entwickelt die Methode weiter, gibt zum Jour-Fixe ein Update zum Stand und teilt mit, wenn es Herausforderungen gibt. Das Team unterstützt dabei jeden Leiter und gibt Feedback bei jeder Statusvorstellung. 

\section{Datensatz und Problemstellung}

\subsection{Datensatz}
Die Datensätze stammen von Kaggle: \url{https://www.kaggle.com/datasets/urbanbricks/wikipedia-promotional-articles}. Ein Datensatz enthält Wikipedia-Artikel, die als \emph{promotional} (also werbend) klassifiziert sind. Dabei sind folgende Label vergeben:
\begin{itemize}
    \item advert – „Dieser Artikel enthält Inhalte, die wie eine Werbeanzeige verfasst sind.“
\item coi – „Ein Hauptautor dieses Artikels scheint eine enge Verbindung zu seinem Thema zu haben.“
\item fanpov – „Dieser Artikel ist möglicherweise aus der Sicht eines Fans geschrieben, statt aus einer neutralen Perspektive.“
\item pr – „Dieser Artikel liest sich wie eine Pressemitteilung oder ein Nachrichtenartikel oder basiert weitgehend auf routinemäßiger Berichterstattung oder Sensationslust.“
\item resume – „Dieser biografische Artikel ist wie ein Lebenslauf geschrieben.“
\end{itemize}
Der zweite Datensatz enthält Wikipedia Artikel die \emph{nicht-promotional} klassifiziert sind.

\subsection{Problemdefinition}

Das Ziel dieses Projekts ist die Entwicklung von Modellen zur automatisierten Klassifikation von Wikipedia-Artikeln als \emph{promotional} (werblich) oder \emph{nicht-promotional}. Wikipedia strebt nach objektiven und neutralen Inhalten; daher ist die Identifizierung von Artikeln mit werbenden Charakter von großer Bedeutung, um die sachliche Qualität der Plattform zu gewährleisten.

\subsection{Zielsetzung}

Die Hauptziele des Projekts sind:

\begin{itemize} \item Entwicklung von drei klassischen maschinellen Lernmodellen und einem Deep-Learning-Modell zur Klassifikation von Wikipedia-Artikeln. \item Vergleich der Modelle anhand von Leistungsmetriken wie Genauigkeit, Präzision, Recall und F1-Score. \item Identifikation des Modells mit der besten Leistung für die gegebene Aufgabe. \end{itemize}

\section{Ansätze}
Blubb

\section{Experimente}
Blubb
\subsection{Evaluationsmetriken}
\begin{enumerate}
    \item 
Sei $D = \{(x^{(1)}, y^{(1)}), \dots, (x^{(m)}, y^{(m)})\}$ ein Datensatz und $clf: \mathbb{R}^n \to \{0, 1\}$ ein (binärer) Klassifikator. Das \textbf{Genauigkeitsmaß} $acc$ von $clf$ bezüglich $D$ ist definiert durch
\begin{equation}
    acc(D, clf) = \frac{1}{m} \sum_{i=1}^{m} \left(1 - \left|y^{(i)} - clf(x^{(i)})\right|\right)
\end{equation}
    
\item 
Wir definieren

\begin{equation}
    TP(D, clf) = |\{i \mid y^{(i)} = 1, clf(x^{(i)}) = 1\}|
\end{equation}
\begin{equation}
    TN(D, clf) = |\{i \mid y^{(i)} = 0, clf(x^{(i)}) = 0\}|
\end{equation}
\begin{equation}
    FP(D, clf) = |\{i \mid y^{(i)} = 0, clf(x^{(i)}) = 1\}|
\end{equation}
\begin{equation}
    FN(D, clf) = |\{i \mid y^{(i)} = 1, clf(x^{(i)}) = 0\}|
\end{equation}

Die \textit{Konfusionsmatrix} von $clf$ bzgl. $D$ stellt die vier oben genannten Werte tabellarisch wie folgt dar:

\[
\begin{array}{|c|c|c|}
\hline
 & y = 1 & y = 0 \\
\hline
clf = 1 & TP(D, clf) & FP(D, clf) \\
clf = 0 & FN(D, clf) & TN(D, clf) \\
\hline
\end{array}
\]
\item
Sei $D = \{(x^{(1)}, y^{(1)}), \dots, (x^{(m)}, y^{(m)})\}$ ein Datensatz und $clf: \mathbb{R}^n \to \{0, 1\}$ ein ~(binärer) Klassifikator. Definiere
\begin{itemize}
    \item \textbf{Präzision:}
    \begin{equation}
    \text{prec}(D, clf) = \frac{TP(D, clf)}{TP(D, clf) + FP(D, clf)}
     \end{equation}
    \item \textbf{Recall:}
 \begin{equation}
    \text{rec}(D, clf) = \frac{TP(D, clf)}{TP(D, clf) + FN(D, clf)}
    \end{equation}
    \item \textbf{F1:}
    \begin{equation}
    \text{F1}(D, clf) = \frac{2 \cdot \text{prec}(D, clf) \cdot \text{rec}(D, clf)}{\text{prec}(D, clf) + \text{rec}(D, clf)}
    \end{equation}
\end{itemize}
\end{enumerate}

\section{Ausblick}
Blubb

\section{Zusammenfassung und Fazit}
Blubb
% References
\addreferences

\makestatement{5}

\end{document}
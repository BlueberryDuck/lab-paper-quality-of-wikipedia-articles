%%% Choose between 16:9 and 4:3 format by commenting out/uncommenting one of the following lines:
\documentclass[aspectratio=169]{beamer} % 16:9
% \documentclass{beamer} % 4:3

%=========================================================================================================================

\usepackage[english]{babel}     % English language
\usepackage[latin1]{inputenc}   % Input encoding
\usepackage{tikz}               % For creating graphics
\usepackage{subfig}
\usepackage[mode=buildnew]{standalone}
\usepackage{url}                % For including urls
\usepackage{tabularx}           % For better tables
\usepackage{xcolor}             % Für bunte Farbe :)

\usetheme{aig}                  % Set beamer theme

%=========================================================================================================================
\title{Qualit\"at von Wikipedia-Artikeln}

\author[]{Alexander Kunze, Sebastian Bunge, Johannes Kr\"amer, Emmanuelle Steenhof, Robin Suxdorf}
\institute{Artificial Intelligence Group,\\
University of Hagen, Germany}
\date{\today}
%=========================================================================================================================
\logo{\includegraphics[width=3cm]{figures/logoaig.png}}
%=========================================================================================================================

\begin{document}

%=========================================================================================================================

% frame
% block
% alertblock
% exampleblock

% \highlight{}
% \darkhighlight{}
% \yellowhighlight{}
% \mathhighlight{}
% \darkmathhighlight{}
% \yellowmathhighlight{}

% appendix

\begin{frame}
    \titlepage
\end{frame}
\nologo

\begin{frame}
    \begin{block}{5. Ansatz}
      Probleme: Schlechte Multilabelklassifizierung der ersten vier Ansätze.
      \\Analyse: Unterscheidung der Promotional aufgrund von Thema
      \\Ziel:
      Einbezug von Kontext/Bedeutung
      \\Ideen:
      \begin{itemize}
      \item Vorverarbeitungsmethode erstellen
      \item Transformerarchitektur verwenden
      \end{itemize}      
    \end{block}
 
\end{frame}

\begin{frame}
    \begin{block}{Transformerarchitektur}
     Modellwahl: DistilBERT \\
     Vorteile: Besondere Vorteile von BERT in der Erkennung von Kontext
     \\Architektur:
\begin{itemize}
	\item Darstellung: DistilBERT Tokenizer
     \item Attention: Scaled Dot Product Attention (SDPA)
     \item Aktivierungsfunktion: $GeLu(x) \approx {0.5 \cdot x \cdot (1+ tanh{({x \over {\sqrt{2}}})})} $
     
\end{itemize}        
    \end{block}
 
\end{frame}


\begin{frame}
\begin{block}{Zusammenfassung}
Errungenschaften:
\begin{itemize}
\item Daten analysiert
\item Datensatz mit Wikipedia Dump erweitert
\item Problemstellung erfasst
\item Datensatz für Mashine Learning Verfahren vorbereitet.
\item Drei Klassische Modelle implementiert
\item Zwei Neuronale Methode implementiert
\item Ergebnisse Evaluiert
\end{itemize}
Ergebnisse:
\begin{itemize}
\item Datensatz aus Wikipedia Dump erstellt
\item Pipeline zur Klassifizierung von Wikipediaartikeln implementiert
\end{itemize}
\end{block}
\end{frame}
\begin{frame}

\begin{block}{Zusammenfassung}

Misserfolge
\begin{itemize}
\item Datenaugmentierung
\item Entwicklung von Vorverarbeitung zur Erkennung von Kontext
\end{itemize}
Erweiterungsmöglichkeiten:
\begin{itemize}
\item Weitere klassische und neuronalen Ansätze implementieren und evaluieren
\item Ganzen Wikipedia Dump verwenden
\item Verwendung von SetFit
\item Verwendung weiterer Modelle des Maschiniellen Lernens
\end{itemize}
\end{block}
\end{frame}

\end{document}

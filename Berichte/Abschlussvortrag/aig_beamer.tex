%%% Choose between 16:9 and 4:3 format by commenting out/uncommenting one of the following lines:
\documentclass[aspectratio=169]{beamer} % 16:9
% \documentclass{beamer} % 4:3

%=========================================================================================================================

\usepackage[english]{babel}     % English language
\usepackage[utf8]{inputenc}     % Input encoding changed to utf8 for proper rendering of umlauts
\usepackage{tikz}               % For creating graphics
\usepackage{subfig}
\usepackage[mode=buildnew]{standalone}
\usepackage{url}                % For including urls
\usepackage{tabularx}           % For better tables
\usepackage{xcolor}             % Für bunte Farbe :)

\usetheme{aig}                  % Set beamer theme

%=========================================================================================================================
\title{Qualität von Wikipedia-Artikeln}
\author[]{Alexander Kunze, Sebastian Bunge, Johannes Krämer, Emmanuelle Steenhof, Robin Suxdorf}
\institute{Artificial Intelligence Group,\\
University of Hagen, Germany}
\date{\today}
%=========================================================================================================================
\logo{\includegraphics[width=3cm]{figures/logoaig.png}}
%=========================================================================================================================

\begin{document}

%=========================================================================================================================

% frame
% block
% alertblock
% exampleblock

% \highlight{}
% \darkhighlight{}
% \yellowhighlight{}
% \mathhighlight{}
% \darkmathhighlight{}
% \yellowmathhighlight{}

% appendix

\begin{frame}
    \titlepage
\end{frame}
\nologo

\begin{frame}{Motivation}
    (Screenshot guter Artikel)
\end{frame}

\begin{frame}{Motivation}
    (Screenshot schlechter Artikel)
\end{frame}

\section{Daten}

\begin{frame}{Daten}

\end{frame}

\subsection{Datensatz}

\begin{frame}{Datensatz}
    (Verteilung good/promo)
    (Verteilung labels)
\end{frame}

\subsection{Problemstellung}

\begin{frame}{Problemstellung}

\end{frame}

\subsection{Weitere Daten}

\begin{frame}{Weitere Daten}

\end{frame}

\subsection{Datenvorverarbeitung}

\begin{frame}{Datenvorverarbeitung}
    \begin{block}{Datenvorverarbeitung}
        % Kopiert von Zwischenpräsentation wird angepasst von Sebastian
        \begin{itemize}
            \item Entfernung von Sonderzeichen und Kleinbuchstabierung
            \item Entfernung von führenden und folgenden Leerzeichen
            \item Optional Stopwörter und Zahlen entfernen
        \end{itemize}
    \end{block}
\end{frame}

\subsection{Vektorisierung}

\begin{frame}{Vektorisierung}
    \begin{block}{Vektorisierung}
        % Kopiert von Zwischenpräsentation wird angepasst von Sebastian
        Textrepräsentation mittels TF-IDF-Vektorisierung:
        \begin{itemize}
            \item Maximale Anzahl von Features
            \item n-Gramm-Bereich
            \item Minimale Dokumentenfrequenz (\texttt{min\_df})
            \item Maximale Dokumentenfrequenz (\texttt{max\_df})
        \end{itemize}
    \end{block}
\end{frame}

\section{Ansätze}

\begin{frame}{Ansätze}
    \begin{block}{Klassische Verfahren}
        \begin{itemize}
            \item Bayes-Klassifikator
            \item Support Vector Machine
            \item Logistische Regression
        \end{itemize}
    \end{block}
    \begin{block}{Deep Learning}
        \begin{itemize}
            \item \yellowhighlight{CNN}
            \item \yellowhighlight{5. Ansatz}
        \end{itemize}
    \end{block}
\end{frame}

\subsection{Klassische Verfahren}

\begin{frame}{Klassische Verfahren}
    Logistische Regression
\end{frame}

\begin{frame}{Klassische Verfahren}
    Naive Bayes Klassifikator
\end{frame}

\begin{frame}{Klassische Verfahren}
    Support Vector Machine
\end{frame}

\subsection{Deep Learning}

\begin{frame}{Deep Learning}
    CNN
\end{frame}

\begin{frame}{Deep Learning}
    \begin{block}{5. Ansatz}
        Probleme: Schlechte Multilabelklassifizierung der ersten vier Ansätze. \\
        Analyse: Unterscheidung der Promotional aufgrund von Thema: \\
        Ziel:
        Einbezug von Kontext/Bedeutung \\
        Ideen:
        \begin{itemize}
            \item Vorverarbeitungsmethode erstellen
            \item Transformerarchitektur verwenden
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}{Deep Learning}
    \begin{block}{Transformerarchitektur}
        Modellwahl: DistilBERT \\
        Vorteile: Besondere Vorteile von BERT in der Erkennung von Kontext \\
        Architektur:
        \begin{itemize}
            \item Darstellung: DistilBERT Tokenizer
            \item Attention: Scaled Dot Product Attention (SDPA)
            \item Aktivierungsfunktion: $GeLu(x) \approx {0.5 \cdot x \cdot (1+ tanh({\frac{x}{\sqrt{2}}}))} $
        \end{itemize}
    \end{block}
\end{frame}

\section{Zusammenfassung}

\begin{frame}{Zusammenfassung}
    \begin{block}{Zusammenfassung}
        Errungenschaften:
        \begin{itemize}
            \item Daten analysiert
            \item Datensatz mit Wikipedia Dump erweitert
            \item Problemstellung erfasst
            \item Datensatz für Mashine Learning Verfahren vorbereitet.
            \item Drei Klassische Modelle implementiert
            \item Zwei Neuronale Methode implementiert
            \item Ergebnisse Evaluiert
        \end{itemize}
        Ergebnisse:
        \begin{itemize}
            \item Datensatz aus Wikipedia Dump erstellt
            \item Pipeline zur Klassifizierung von Wikipediaartikeln implementiert
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}{Zusammenfassung}
    \begin{block}{Zusammenfassung}
        Misserfolge
        \begin{itemize}
            \item Datenaugmentierung
            \item Entwicklung von Vorverarbeitung zur Erkennung von Kontext
        \end{itemize}
        Erweiterungsmöglichkeiten:
        \begin{itemize}
            \item Weitere klassische und neuronalen Ansätze implementieren und evaluieren
            \item Ganzen Wikipedia Dump verwenden
            \item Verwendung von SetFit
            \item Verwendung weiterer Modelle des Maschinellen Lernens
        \end{itemize}
    \end{block}
\end{frame}

\end{document}

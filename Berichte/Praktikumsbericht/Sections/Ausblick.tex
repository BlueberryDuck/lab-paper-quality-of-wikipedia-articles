\section{Ausblick}
\label{Ausblick}
Nachdem alle Experimente durchgeführt und evaluiert worden sind, werden die gesammelten Erfahrungen festgehalten.

\subsection{Erfolglose Versuche}
Um gute Modelle zu finden, die die Aufgabe lösen konnten, gab es einige Versuche, die zwar vielversprechend schienen, aber in der Praxis keine erfolgreichen Ergebnisse lieferten.

\subsubsection{Easy Data Augmentation}
\label{EDA}
Um das Ungleichgewicht bei unterrepräsentierten Sublabeln auszugleichen, wurde versucht, zusätzliche Texte mithilfe von Easy Data Augmentation \cite{Wei2019} zu generieren. Dabei wurden Synonymaustausch, zufällige Ersetzungen, Löschungen und Wortvertauschungen angewendet. Ein erster Testlauf  auf den augmentierten Daten zeigte eine Verbesserung  des Macro Average Recall für die unterrepräsentierten Sublabeln. Allerdings haben die so trainierten Modelle auf den Originaldaten eine deutlich schlechtere Leistung gehabt, weswegen dieser Ansatz verworfen wurde.

\subsubsection{Gram-Schmidt Verfahren zur Erstellung von Embedding}
Das Gram-Schmidt-Verfahren wurde zur Erzeugung von Vektorrepräsentationen eingesetzt, indem $n$ Artikel aus $m$ Kategorien eine Orthonormalbasis für einen $m\cdot n$-dimensionalen Raum definierten. Die Skalarprodukte der verbleibenden Vektoren mit dieser Basis dienten als Koordinaten der Artikel in diesem Raum. Ein sehr ähnlicher Ansatz findet sich bei Yang et al. \cite{Yang2019}. Da die Methode zu einer Verschlechterung der Ergebnisse führte, wurde sie verworfen. Eine detaillierte Beschreibung der Implementierung und der Experimente ist im Skript <Quelle einfügen> zu finden.

\subsubsection{Klassifizierung einzelner Wörter als Kodierung}
Da die ersten vier Ansätze Schwächen in der Multilabel-Klassifikation zeigten, wurde ein alternativer Ansatz erprobt, bei dem einzelne Wörter klassifiziert und anschließend so kodiert wurden, dass ähnlich klassifizierte Wörter durch nahe beieinanderliegende Vektoren repräsentiert werden. Das Verfahren verlief wie folgt: Zunächst wurden alle Artikel in Wörter zerlegt, die das Label ihres jeweiligen Artikels erhielten. Wörter mit mehreren Zugehörigkeiten wurden als separate Klassen behandelt. Anschließend erfolgte eine Klassifikation mittels eines Modells wie einer Support Vector Machine. Da bereits die Klassifikation einzelner Wörter unzureichende Ergebnisse lieferte, wurde dieser Ansatz nicht weiterverfolgt.


\subsection{Ausbaumöglichkeiten}
Um die Forschung auf diesem Gebiet fortzuführen, könnte man, weitere Modelle hinzufügen. Besonders interessant könnten dabei Entscheidungsbäume sein, um abzulesen welche Wörter den grössten auf die Klassifizierug haben. Eine weitere Architektur, die positive Effekte zur Bekämpfung der ungleich verteilten Label haben könnte, wäre SetFit \cite{Tunstall2022}. Ausserdem lag der Fokus während dem Praktikum eher auf dem Text der einzelnen Artikel, während die URL nicht zur Anwendung kam. Daher könnte man versuchen, in einem weiteren Schritt, eher auf dieses Attribut zu fokussieren und die Metadaten der einzelnen Seiten zur Klassifizierung zu verwenden. Dabei könnten sowohl maschinielle Methoden zur Anwendung kommen oder Algorithmen mit denen man z.B. bestimmen könnte, wie sehr die Artikel miteinander vernetzt sind.

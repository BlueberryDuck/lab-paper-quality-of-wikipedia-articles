\section{Experimente}
% Text?

\subsection{Projektstruktur}
\label{sec:projektstruktur}
Zu Beginn des Projekts arbeiteten alle Teilnehmenden explorativ in Jupyter Notebooks, um ein grundlegendes Verständnis der Daten zu entwickeln und erste Modellierungsansätze zu testen. Um konsistente Datenverarbeitung und vergleichbare Ergebnisse zu gewährleisten, wurden gemeinsame Methoden und abstrakte Klassen entwickelt und in einer Python-Bibliothek implementiert.

Diese Pipeline \texttt{main.py} verwendet gemeinsame Methoden zum Laden, Vorverarbeiten, Extrahieren von Merkmalen, Trainieren von Modellen und Evaluieren von Ergebnissen. Diese Komponenten sind in \texttt{src/} implementiert, sodass sie sowohl in die Pipeline als auch in Jupyter Notebooks importiert werden können. Die Pipeline wird über YAML-Konfigurationsdateien \texttt{configs/} gesteuert, die alle relevanten Einstellungen wie Dateipfade, aktivierte Vorverarbeitungsschritte, Modellparameter und Evaluationskriterien beinhalten. Dadurch ist eine einfache Anpassung zum Testen verschiedener Parameter und Anwendungsfälle möglich. Zudem können einzelne Pipeline-Schritte partiell ausgeführt werden, zum Beispiel können die Vorverarbeitungsschritte aus vorherigen Läufen geladen werden, um ausschließlich das Modell mit variierenden Parametern zu trainieren und so die Laufzeit deutlich zu verringern.

Die Modelle wurden als Klassen implementiert, die von einer abstrakten Basisklasse erben. Dadurch wird eine einheitliche Schnittstelle für die Pipeline bereitgestellt, die es ermöglicht, verschiedene Modelle einfach zu vergleichen. Die klassischen maschinellen Lernmethoden können ohne weiteres über Konfigurationsdateien ausgewählt werden. Die Deep Learning Modelle, wie CNNs und Transformer, werden aufgrund ihrer zusätzlichen Komplexität in Jupyter Notebooks mit kleineren Anpassungen ausgeführt und evaluiert, welche aber die gleichen Methoden aus \texttt{src/} verwenden.

\subsection{Evaluationsmetriken}
Sei $D$ ein Datensatz. In der binären Klassifikation liegt unser Hauptfokus primär auf der Optimierung des \textbf{Recalls} $\rec(D, \clf)$ und sekundär auf der \textbf{Precision} $\prec(D, \clf)$. Dabei ist $\clf\colon\mathbb{R}^d\to \{0, 1\}$ ein binärer Klassifikator.\\

Für die Multilabel-Klassifikation betrachten wir den Klassifikator $\clf\colon\mathbb{R}^d\to\{0, 1\}^k$, wobei $k$ die Anzahl der verschiedenen Labels ist (in diesem Bericht $k=5$). Komponentenweise können wir $\clf$ auch schreiben als $\clf = (\clf_i)_{1\leq i\leq k}$, wobei $\clf_i\colon\mathbb{R}^d\to\{0, 1\}$ ein binärer Klassifikator ist. Wir definieren den \textbf{Macro Average Recall} von $\clf$ als
\begin{equation*}
    \operatorname{macro\,avg\,rec}(D, \clf) = \frac{1}{k}\sum_{i=1}^k\rec (D, \clf_i).
\end{equation*}

\subsection{Ergebnisse}
\begin{center}
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        Ansatz                       & acc  & prec & rec  & F1   \\
        \hline
        Logistische Regression       & 0.99 & 0.98 & 0.92 & 0.93 \\
        Bayes-Klassifikator          & 0.95 & 0.98 & 0.93 & 0.91 \\
        Support Vector Machine       & 0.94 & 0.92 & 0.89 & 0.95 \\
        Convolutional Neural Network & 0.91 & 0.94 & 0.92 & 0.96 \\
        Transformer                  & 0.97 & 0.95 & 0.92 & 0.93 \\
        \hline
    \end{tabular}
\end{center}
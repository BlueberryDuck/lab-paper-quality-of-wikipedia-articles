\section{Experimente}

\subsection{Projektstruktur}
\label{sec:projektstruktur}
Zu Beginn des Projekts arbeiteten alle Teilnehmenden explorativ in Jupyter Notebooks, um ein grundlegendes Verständnis der Daten zu entwickeln und erste Modellierungsansätze zu testen. Um konsistente Datenverarbeitung und vergleichbare Ergebnisse zu gewährleisten, wurde eine einheitliche Machine-Learning-Pipeline entwickelt.

Diese Pipeline standardisiert die wesentlichen Schritte - von der Datenverarbeitung über die Modellierung bis hin zur Evaluation - und besteht aus den folgenden modularen Komponenten:

\begin{itemize}
    \item \textbf{DataLoader} - Laden und Zusammenführen der Daten
    \item \textbf{Preprocessing} - Vorverarbeitung der Textdaten (z.B. Entfernen von Stopwörtern)
    \item \textbf{Feature Extraction} - Extraktion von Merkmalen (z.B. mittels TF-IDF oder GloVe-Vectorizer)
    \item \textbf{Model} - Training und Hyperparameter-Optimierung
    \item \textbf{Evaluator} - Auswertung der Modellergebnisse
\end{itemize}

Diese Komponenten sind in einer Python-Bibliothek (\texttt{src/}) implementiert, sodass sie sowohl eigenständig als auch in Jupyter Notebooks eingesetzt werden können. Die Pipeline wird über YAML-Konfigurationsdateien gesteuert, die alle relevanten Einstellungen wie Dateipfade, Vorverarbeitungsschritte, Modellparameter und Evaluationskriterien beinhalten. Dadurch ist eine flexible Anpassung an unterschiedliche Use-Cases möglich. Zudem können einzelne Pipeline-Schritte partiell ausgeführt werden - etwa kann die Feature Extraction aus vorherigen Läufen geladen werden, um ausschließlich das Modell mit variierenden Parametern zu trainieren.

Die einheitliche Struktur erleichtert die Weiterentwicklung und Wartung des Codes, da alle Pipeline-Schritte klar getrennt sind. Für detaillierte Implementierungsinformationen und Konfigurationsdetails wird auf das GitHub-Repository verwiesen.

\subsection{Evaluationsmetriken}
Für den Vergleich der verschiedenen Modelle wurden die folgenden Metriken verwendet. Dabei sei $D = \{(x^{(1)}, y^{(1)}), \dots, (x^{(m)}, y^{(m)})\}$ und $\clf\colon\mathbb{R}^n \to \{0, 1\}$ ein binärer Klassifikator. Zunächst definieren wir

\begin{align*}
    \tp(D, \clf) &= |\{i \mid y^{(i)} = 1, \clf(x^{(i)}) = 1\}| \\
    \tn(D, \clf) &= |\{i \mid y^{(i)} = 0, \clf(x^{(i)}) = 0\}| \\
    \fp(D, \clf) &= |\{i \mid y^{(i)} = 0, \clf(x^{(i)}) = 1\}| \\
    \fn(D, \clf) &= |\{i \mid y^{(i)} = 1, \clf(x^{(i)}) = 0\}|
\end{align*}

und aufbauend darauf die vier Metriken

\begin{itemize}
    \item \textbf{Genauigkeit:}
        \begin{equation*}
            \acc(D, \clf) = \frac{\tp(D, \clf) + \tn(D, \clf)}{\tp(D, \clf) + \tn(D, \clf) + \fp(D, \clf) + \fn(D, \clf)}
        \end{equation*}
    \item \textbf{Präzision:}
        \begin{equation*}
            \prec(D, \clf) = \frac{\tp(D, \clf)}{\tp(D, \clf) + \fp(D, \clf)}
        \end{equation*}
    \item \textbf{Recall:}
        \begin{equation*}
            \rec(D, \clf) = \frac{\tp(D, \clf)}{\tp(D, \clf) + \fn(D, \clf)}
        \end{equation*}
    \item \textbf{F1:}
        \begin{equation*}
            \fscore(D, \clf) = \frac{2 \cdot \prec(D, \clf) \cdot \rec(D, \clf)}{\prec(D, \clf) + \rec(D, \clf)}
        \end{equation*}
\end{itemize}

\subsection{Ergebnisse}
\begin{center}
    \begin{tabular}{|c|c|c|c|c|}
    \hline
        Ansatz & acc & prec & rec & F1 \\
        \hline
        Logistische Regression & 0.99 & 0.98 & 0.92 & 0.93 \\
        Bayes-Klassifikator & 0.95 & 0.98 & 0.93 & 0.91 \\
        Support Vector Machine & 0.94 & 0.92 & 0.89 & 0.95 \\
        Convolutional Neural Network & 0.91 & 0.94 & 0.92 & 0.96 \\
        Transformer & 0.97 & 0.95 & 0.92 & 0.93 \\
        \hline
    \end{tabular}
\end{center}
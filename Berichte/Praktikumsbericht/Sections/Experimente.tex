\section{Experimente}

\subsubsection{Projektstruktur}
\label{sec:projektstruktur}
Zu Beginn des Projekts arbeiteten alle Teilnehmenden explorativ in Jupyter Notebooks, um ein grundlegendes Verständnis der Daten zu entwickeln und erste Modellierungsansätze zu testen. Um konsistente Datenverarbeitung und vergleichbare Ergebnisse zu gewährleisten, wurde eine einheitliche Machine-Learning-Pipeline entwickelt.

Diese Pipeline standardisiert die wesentlichen Schritte - von der Datenverarbeitung über die Modellierung bis hin zur Evaluation - und besteht aus den folgenden modularen Komponenten:

\begin{itemize}
    \item \textbf{DataLoader} - Laden und Zusammenführen der Daten
    \item \textbf{Preprocessing} - Vorverarbeitung der Textdaten (z.B. Entfernen von Stopwörtern)
    \item \textbf{Feature Extraction} - Extraktion von Merkmalen (z.B. mittels TF-IDF oder GloVe-Vectorizer)
    \item \textbf{Model} - Training und Hyperparameter-Optimierung
    \item \textbf{Evaluator} - Auswertung der Modellergebnisse
\end{itemize}

Diese Komponenten sind in einer Python-Bibliothek (\texttt{src/}) implementiert, sodass sie sowohl eigenständig als auch in Jupyter Notebooks eingesetzt werden können. Die Pipeline wird über YAML-Konfigurationsdateien gesteuert, die alle relevanten Einstellungen wie Dateipfade, Vorverarbeitungsschritte, Modellparameter und Evaluationskriterien beinhalten. Dadurch ist eine flexible Anpassung an unterschiedliche Use-Cases möglich. Zudem können einzelne Pipeline-Schritte partiell ausgeführt werden - etwa kann die Feature Extraction aus vorherigen Läufen geladen werden, um ausschließlich das Modell mit variierenden Parametern zu trainieren.

Die einheitliche Struktur erleichtert die Weiterentwicklung und Wartung des Codes, da alle Pipeline-Schritte klar getrennt sind. Für detaillierte Implementierungsinformationen und Konfigurationsdetails wird auf das GitHub-Repository verwiesen.

\subsection{Evaluationsmetriken}
Um die Datensätze miteinander vergleichen zu können, kamen verschiedene Metriken zu Anwendung
\begin{enumerate}
    \item
          Sei $D = \{(x^{(1)}, y^{(1)}), \dots, (x^{(m)}, y^{(m)})\}$ ein Datensatz und $clf: \mathbb{R}^n \to \{0, 1\}$ ein (binärer) Klassifikator. Das \textbf{Genauigkeitsmaß} $acc$ von $clf$ bezüglich $D$ ist definiert durch
          \begin{equation}
              acc(D, clf) = \frac{1}{m} \sum_{i=1}^{m} \left(1 - \left|y^{(i)} - clf(x^{(i)})\right|\right)
          \end{equation}

    \item
          Wir definieren

          \begin{equation}
              TP(D, clf) = |\{i \mid y^{(i)} = 1, clf(x^{(i)}) = 1\}|
          \end{equation}
          \begin{equation}
              TN(D, clf) = |\{i \mid y^{(i)} = 0, clf(x^{(i)}) = 0\}|
          \end{equation}
          \begin{equation}
              FP(D, clf) = |\{i \mid y^{(i)} = 0, clf(x^{(i)}) = 1\}|
          \end{equation}
          \begin{equation}
              FN(D, clf) = |\{i \mid y^{(i)} = 1, clf(x^{(i)}) = 0\}|
          \end{equation}

          Die \textit{Konfusionsmatrix} von $clf$ bzgl. $D$ stellt die vier oben genannten Werte tabellarisch wie folgt dar:

          \[
              \begin{array}{|c|c|c|}
                  \hline
                          & y = 1      & y = 0      \\
                  \hline
                  clf = 1 & TP(D, clf) & FP(D, clf) \\
                  clf = 0 & FN(D, clf) & TN(D, clf) \\
                  \hline
              \end{array}
          \]
    \item
          Sei $D = \{(x^{(1)}, y^{(1)}), \dots, (x^{(m)}, y^{(m)})\}$ ein Datensatz und $clf: \mathbb{R}^n \to \{0, 1\}$ ein ~(binärer) Klassifikator. Definiere
          \begin{itemize}
              \item \textbf{Präzision:}
                    \begin{equation}
                        \text{prec}(D, clf) = \frac{TP(D, clf)}{TP(D, clf) + FP(D, clf)}
                    \end{equation}
              \item \textbf{Recall:}
                    \begin{equation}
                        \text{rec}(D, clf) = \frac{TP(D, clf)}{TP(D, clf) + FN(D, clf)}
                    \end{equation}
              \item \textbf{F1:}
                    \begin{equation}
                        \text{F1}(D, clf) = \frac{2 \cdot \text{prec}(D, clf) \cdot \text{rec}(D, clf)}{\text{prec}(D, clf) + \text{rec}(D, clf)}
                    \end{equation}
          \end{itemize}
\end{enumerate}
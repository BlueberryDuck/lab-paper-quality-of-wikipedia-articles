\subsection{Logistische Regression}

Für die Klassifikation von Wikipedia-Artikeln wurde eine logistische Regression als Modell eingesetzt. Zur Feinabstimmung des Modells wurden folgende spezifische Parameter variiert. Für die Regularisierung wurden zwei Varianten getestet: Die \texttt{l1}-Regularisierung (Lasso) setzt irrelevante Merkmale auf null und führt somit zu einem sparsamen Modell. Die \texttt{l2}-Regularisierung (Ridge) reduziert die Gewichte irrelevanter Merkmale und verstärkt jene, die für die Klassifikation relevanter erscheinen. Neben der Regularisierung spielte das Optimierungsverfahren eine entscheidende Rolle. Zwei Solver wurden evaluiert: Der \texttt{liblinear}-Solver wurde als Standardmethode eingesetzt, da sie sowohl L1- als auch L2-Regularisierung unterstützt. Zusätzlich wurde \texttt{saga}, eine Erweiterung des Stochastic Average Gradient, getestet, die speziell für große Datensätze geeignet ist und ebenfalls mit beiden Regularisierungsarten kompatibel ist.
Ein weiterer wichtiger Parameter war die maximale Anzahl an Iterationen (\texttt{max\_iter}): \texttt{500} und \texttt{1000}.

\subsubsection{Binäre Klassifikation}
Um Artikel als \textit{good} oder \textit{promotional} zu klassifizieren, wurde eine L1-regularisierte logistische Regression eingesetzt. Die Wahl dieses Modells erfolgte aufgrund mehrerer Vorteile:
\begin{itemize}
\item Effizienz: Im Vergleich zu komplexeren Modellen wie neuronalen Netzwerken ist die logistische Regression ressourcenschonend und schnell trainierbar.
\item Robustheit durch Regularisierung: Die L1-Regularisierung führt zu einem sparsamen Modell, indem irrelevante Features eliminiert werden.
\end{itemize} 
Die Daten wurden in Trainings- und Testmengen aufgeteilt. Um die optimale Hyper-parameter-Kombination zu finden, wurde  \textit{GridSearchCV} mit Kreuzvalidierung eingesetzt. Hierbei wurden verschiedene Werte für den Regularisierungsparameter \(C\) sowie unterschiedliche \textit{ngram}-Bereiche getestet. 
Die Ergebnisse zeigten, dass der Ansatz zuverlässig zwischen \textit{good}- und \textit{promotional}-Artikeln unterscheiden konnte. 
\subsubsection{Erweiterung durch Multilabel-Klassifikation und Datenaugmentation}
Zusätzlich zur binären Klassifikation wurde das Problem als \textit{Multilabel-Klassifikation} betrachtet.
Weil ein Artikel mehrere Labels gleichzeitig besitzen kann, wurde ein \textit{One-vs-Rest}-Ansatz mit L1-regularisierter logistischer Regression verwendet.
Da einige Klassen unterrepräsentiert waren, wurde eine Datenaugmentation durchgeführt. Dabei wurden aus Artikeln mit seltenen Labels durch Easy Data Augmentation (EDA) neue Artikel generiert.
Nach der Augmentierung wurde das Modell erneut trainiert und evaluiert. Der Vergleich zeigte kleine Verbesserungen bei den betroffenen Labels, aber auch eine erhebliche Verschlechterung bei der richtigen Identifizierung vom überrepräsentierten Label \textit{advert}. Deshalb wurde EDA verworfen. Das Modell wurde anschließend in die Pipeline des Projektes eingefügt.
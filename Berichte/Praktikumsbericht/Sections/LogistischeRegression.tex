\subsection{Logistische Regression}

Für die Klassifikation von Wikipedia-Artikeln wurde eine logistische Regression als Modell eingesetzt. Bei der Unterscheidung der Hauptlabels reichte eine einfache Implementierung für die binäre Entscheidung. Bei der Klassifikation der Sublabels wurde der OneVsRest-Ansatz gewählt, um jeweils die binäre Entscheidung zu treffen. Um eine optimale Modellkonfiguration zu gewährleisten, wurde eine Hyperparameteroptimierung mittels GridSearch durchgeführt. Zur Feinabstimmung des Modells wurden folgende spezifische Parameter variiert. Für die Regularisierung wurden zwei Varianten getestet: Die \texttt{l1}-Regularisierung (Lasso) setzt irrelevante Merkmale auf null und führt somit zu einem sparsamen Modell. Die \texttt{l2}-Regularisierung (Ridge) reduziert die Gewichte irrelevanter Merkmale und verstärkt jene, die für die Klassifikation relevanter erscheinen. Neben der Regularisierung spielte das \textbf{Optimierungsverfahren} eine entscheidende Rolle. Zwei Solver wurden evaluiert: Der \texttt{liblinear}-Solver wurde als Standardmethode eingesetzt, da sie sowohl L1- als auch L2-Regularisierung unterstützt. Zusätzlich wurde \texttt{saga}, eine Erweiterung des Stochastic Average Gradient, getestet, die speziell für große Datensätze geeignet ist und ebenfalls mit beiden Regularisierungsarten kompatibel ist.
Ein weiterer wichtiger Parameter war die \textbf{maximale Anzahl an Iterationen} (\texttt{max\_iter}): \texttt{500} und \texttt{1000}.

Zur optimalen Abstimmung dieser Hyperparameter wurde eine \textbf{Grid Search} durchgeführt. Dabei wurden verschiedene Kombinationen von Regularisierung, Optimierungsverfahren und Iterationsanzahl systematisch getestet, um die beste Konfiguration für die logistische Regression zu bestimmen.




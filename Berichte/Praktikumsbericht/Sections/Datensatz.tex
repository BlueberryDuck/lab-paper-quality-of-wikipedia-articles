
Bevor die Modellbildung starten konnte, mussten zunächst die Bedingungen geklärt werden. D.h. der Datensatz musste Analysiert werden und eine entsprechende Problemstellung identifiziert werden. Im folgenden wird zunächst der ursprüngliche Datensatz beschrieben und anschliessend erklärt wie dieser in Laufe des Projekts ausgebaut und ergänzt wird. Danach wird daraus abgeleitete Problemstellung erläutert.

\subsection{Ursprünglicher Datensatz}
Die Datensätze stammen von Kaggle: \url{https://www.kaggle.com/datasets/urbanbricks/wikipedia-promotional-articles}. Ein Datensatz enthält Wikipedia-Artikel, die als \emph{promotional} (also werbend) klassifiziert sind. Dabei sind folgende Label vergeben:
\begin{itemize}
    \item advert - „Dieser Artikel enthält Inhalte, die wie eine Werbeanzeige verfasst sind.“
    \item coi - „Ein Hauptautor dieses Artikels scheint eine enge Verbindung zu seinem Thema zu haben.“
    \item fanpov - „Dieser Artikel ist möglicherweise aus der Sicht eines Fans geschrieben, statt aus einer neutralen Perspektive.“
    \item pr - „Dieser Artikel liest sich wie eine Pressemitteilung oder ein Nachrichtenartikel oder basiert weitgehend auf routinemäßiger Berichterstattung oder Sensationslust.“
    \item resume - „Dieser biografische Artikel ist wie ein Lebenslauf geschrieben.“
\end{itemize}
Der zweite Datensatz enthält Wikipedia Artikel die \emph{nicht-promotional} klassifiziert sind. \\
Die beiden Datensätze wurden zusammen verwendet, um die gesamte Datenbasis zu bilden. Insgesamt ergab das \textbf{Anzahl Datensätze einfügen} Daten. Die Label dieser Daten war wie folgt: \\
\textbf{2 Bilder einfügen: 1. Bild einzelne Label, 2. Bild Kombination der Label}


\subsection{Probleme des ursprünglichen Datensatzes}
Wie man anhand des Diagrammes \textbf{Auf Bild referenzieren} sehen kann, sind die Daten ungleich Verteilt. Daten mit dem Label \textit{good} nehmen laut \textbf{Quelle einfügen} nur 0.59\% aller Wikipediaartikel ein. Allerdings sieht man anhand der Grafik, dass sie im Vergleich zu \textbf{Prozentsatz berechnen}. Zum einen führt das zu einem Verhältnis, dass nicht der Realität entspricht, zum anderen kann das die Ergebnisse der trainierten Modelle verschlechtern.



\subsection{Weitere Daten}
Um ein gutes Modell zu erstellen, welches auf Maschiniellem Lernen basiert, braucht man ensprechende Datensätze. Wie in Abschnitt \textbf{Referenz einfügen} besprochen worden ist, ist der ursprüngliche Datensatz nicht ausreichend, um entsprechende Modelle zu trainieren. Aus diesem Grund wurden verschiedene Methoden ausprobiert und verwendet, um den ursprünglichen Datensatz zu erweitern.




\subsubsection{Datensatzerweiterung durch Wikimedia Dump}
Die naheliegenste Methode zur Erweiterung eines Datensatzes, ist das Hinzuziehen neuer Daten. Aus diesem Grund wurde der Wikimedia Dump \textbf{Quelle hinzufügen} hinzugezogen. Dieser Datensatz ist ein offizieller Datensatz von Wikipedia, in dem Artikel enthalten sind, die durch Wikipedia rausgefiltert worden sind. Dadurch konnten \textbf{Anzahl ergänzen} Datensätze hinzugezogen werden. Diese waren \textit{promotional} Datensätze. In Abschnitt \textbf{Referenz ergänzen} wird erklärt, wie die Datensätze eingelesen worden sind und in das richtige Format gebracht worden sind.

\subsubsection{Augmentierung der Daten}
Da es nicht sicher ist, ob der Wikimedia Dump das Problem volkommen lösen kann, wurde neben dem Hinzuziehen weiterer Daten auch versucht die Daten zu Augmentieren. Dabei sollten besonders untervetretene Klassen mehr Repräsentanten kriegen. Dabei wurden verschiedene Methoden ausprobiert, um die Daten zu Augmentieren. Diese Methoden werden in \textbf{Referenz ergänzen} vorgestellt.

\subsection{Problemdefinition}
Das Ziel dieses Projekts ist die Entwicklung von Modellen zur automatisierten Klassifikation von Wikipedia-Artikeln als \emph{promotional} (werblich) oder \emph{nicht-promotional}. Dabei wird ebenfalls klassifiziert, wie ein Artikel Promotional ist, also z.B. ob er eine Werbung, ein PR-Artikel usw. ist. Wikipedia strebt nach objektiven und neutralen Inhalten; daher ist die Identifizierung von Artikeln mit werbenden Charakter von großer Bedeutung, um die sachliche Qualität der Plattform zu gewährleisten.

\subsection{Zielsetzung}

Die Hauptziele des Projekts sind:

\begin{itemize} \item Entwicklung von drei klassischen maschinellen Lernmodellen und einem Deep-Learning-Modell zur Klassifikation von Wikipedia-Artikeln. \item Vergleich der Modelle anhand von Leistungsmetriken wie Genauigkeit, Präzision, Recall und F1-Score. \item Identifikation des Modells mit der besten Leistung für die gegebene Aufgabe. \end{itemize}
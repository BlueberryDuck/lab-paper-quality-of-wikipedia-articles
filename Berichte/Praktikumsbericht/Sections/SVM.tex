\subsection{Support Vector Machine}
\label{SVM}

Die Support Vector Machine (SVM) ist ein überwacht lernendes Verfahren zur Klassifikation, das darauf abzielt, eine optimale Entscheidungsgrenze (Hyperebene) zwischen den Klassen zu finden. Wie zum Beispiel von Joachims in \cite{textCategorizationWithSVM} beschrieben, eignet sich das Verfahren besonders gut zur Textkategorisierung, da es mit der dabei auftretenden hohen Dimensionalität und dünnbesetzten Vektoren umgehen kann und da viele Textkategorisierungen gut linear separierbar sind.

Im Rahmen des Projekts wurden verschiedene Varianten der SVM getestet: Zunächst die \textit{scikit-learn}-Implementierung \textit{SVC} mit den Kernelfunktionen \textit{linear}, \textit{rbf} und \textit{sigmoid}, wobei auf dem vorliegenden Datensatz der lineare Kernel leicht bessere Ergebnisse lieferte als die Alternativen RBF und Sigmoid. Anschließend wurde die \textit{scikit-learn}-Implementierung \textit{LinearSVC} getestet, welche ausschließlich lineare Kernel unterstützt.  Um möglichst gute Hyper-Parameter zu finden, wurde \textit{GridSearchCV} zur Optimierung eingesetzt. \textit{LinearSVC} und \textit{SVC} mit linearem Kernel lieferten nahezu identische Ergebnisse, allerdings skalierte \textit{LinearSVC} sehr viel besser und ließ sich auf dem vorliegenden Datensatz in einem Bruchteil der Zeit trainieren, die für \textit{SVC} benötigt wurde. Für die weiteren Auswertungen wurde daher \textit{LinearSVC} gewählt.

Die SVM wurde als Option in die bestehende Machine-Learning-Pipeline integriert. Über eine Konfigurationsdatei kann gesteuert werden, ob \textit{LinearSVC} oder \textit{SVC} mit verschiedenen Kernelfunktionen verwendet werden soll. Grid Search ist ebenfalls über die Konfiguration aktivierbar.

In ersten Durchläufen wurde eine überraschend hohe Accuracy von >99\% ermittelt. Diese basierte allerdings auf einem Problem im Train-Test-Split und sank nach Behebung des Problems auf realistische Werte. Um darüber hinaus Fehler in der Umsetzung ausschließen zu können, wurde eine Funktion implementiert, um eine zufällig ausgewählten Teilmenge der Daten mit einem falschen Label zu versehen. Hierdurch sank die Accuracy deutlich, zum Beispiel für 10\% fehlerhafte Labels von 96,7\% auf 84,0\%. Dies ist ebenfalls ein Indiz dafür, dass die hohen Metriken durch eine gute lineare Separierbarkeit erklärt werden können.
